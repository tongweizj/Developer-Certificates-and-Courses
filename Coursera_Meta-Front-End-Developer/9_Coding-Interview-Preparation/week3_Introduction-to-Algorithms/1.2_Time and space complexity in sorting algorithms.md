# Time and space complexity in sorting algorithms

You previously learned that time and space complexity are a means of evaluating code efficiency. In this reading, you will explore time and space complexity in both the selection sort and quicksort algorithms. These are common algorithms that are used to sort data in an array.
您之前了解到时间和空间复杂度是评估代码效率的一种方法。在本文中，您将探索选择排序和快速排序算法的时间和空间复杂性。这些是用于对数组中的数据进行排序的常见算法。

##  **Selection sort**

Selection sort is a sorting algorithm that works from a very simple principle. Take an array to items and iterate from left to right. Starting with the first place on the index, iterate over the entire array and swap this value with the lowest value found to the right of this item. Repeat until the entire array is sorted.
选择排序是一种排序算法，其工作原理非常简单。将数组放入项目并从左到右迭代。从索引的第一个位置开始，迭代整个数组，并将该值与该项目右侧找到的最低值交换。重复此操作，直到整个数组排序完毕。

Selection sort has:
-   Worst case time complexity is O(N^2)
-   Average case time complexity is O(N^2)
-   Best case time complexity is O(N^2)
-   Space complexity: O(1) _Auxiliary_.


To perform selection sort, take the following steps:
要执行选择排序，请执行以下步骤：

-   Find the smallest value and swap it with the first value of the array
-   Find the second smallest value and swap it with the second place in the array
-   Repeat until all items are changed from ordered from smallest to largest


Time complexity is determined in relation to the number of transactions enacted. Given a list of size n, the compiler must search each entry in the list to identify the smallest item, then perform a swap to index location 0. The pseudocode for the algorithm is as below.
时间复杂度取决于所执行的事务数量。给定一个大小为 n 的列表，编译器必须搜索列表中的每个条目以识别最小的项目，然后执行交换到索引位置 0。该算法的伪代码如下。

```

for(i = 0; i < n-1; i++)
  int min_index = i
  for(j = i+1; j < n; j++)
   if(List[j] < List[min_index])
     min_index=j 
  swap(List[i], List[min_index])
```

Line 1 says that the length of the list List must be searched n-1 times. 
Line 2 sets a temporary variable to hold the lowest value. 
Line 3 is an inner loop that must iterate through the loop n-1 times. 
Line 4 checks if the value found in position List\[j\] is smaller than the current lowest value. If so, the position of that element is recorded. At the end of each inner loop, the value found to be the lowest is swapped with position i in the index, i is incremented and the procedure begins again. Always check the next item in the list until every item has been checked.
第 1 行表示列表 List 的长度必须被搜索 n-1 次。
第 2 行设置一个临时变量来保存最小值。
第 3 行是一个内循环，必须迭代该循环 n-1 次。
第 4 行检查在位置 List[j] 中找到的值是否小于当前最小值。如果是，则记录该元素的位置。
在每个内循环结束时，将发现的最低值与索引中的位置 i 交换，i 递增并再次开始该过程。
始终检查列表中的下一项，直到检查完所有项目。

There are four considerations to be made when evaluating this algorithm.
评估该算法时需要考虑四个因素。
1.  Worst case scenario: Given a list sorted in reverse order, how many comparisons are made? The inner and outer loop will have to run n times so it can be determined that worst case \= O(n^2).
2.  Average comparison: Regardless of the order of the list, every item must be checked against average case \= O(n^2).
3.  Best comparison: Given a sorted list of how many comparisons must be made. Again, regardless of the items in the list, every item must be checked, so best case \= O(n^2).
4.  Finally, what is the space complexity of this approach? Because an in-place swap is being performed, no temporary array is required. There are three temporary variables i, j and min\_index; however, these are not dependent on the list size. So, the image doubles the list, and the space complexity does not increase accordingly. Therefore, space complexity \= O(1).

1. 最坏的情况
给定一个按相反顺序排序的列表，需要进行多少次比较？内循环和外循环必须运行 n 次，因此可以确定最坏情况 = O(n^2)
2. 平均比较
无论列表的顺序如何，每个项目都必须根据平均情况进行检查 = O(n^2)。
3. 最佳比较
给出必须进行多少次比较的排序列表。同样，无论列表中的项目如何，都必须检查每个项目，因此最好的情况 = O(n^2)
4. 最后，这种方法的空间复杂度是多少？
由于正在执行就地交换，因此不需要临时数组。有三个临时变量i、j和min_index；然而，这些并不取决于列表的大小。所以，图像将列表加倍，空间复杂度并没有相应增加。因此，空间复杂度 = O(1)。

When evaluating time complexity, a good rule of thumb is to consider what will happen if the list is doubled. Naturally, the inner and outer loops will have to increase by no iterations to match the additional elements in the list. Therefore, it can be concluded that the time complexity increases with the size.
在评估时间复杂度时，一个好的经验法则是考虑如果列表加倍会发生什么。
当然，内部和外部循环必须增加无迭代才能匹配列表中的附加元素。
因此，可以得出结论，时间复杂度随着尺寸的增加而增加。

##  **Quicksort**

Quicksort is a sorting approach that uses a divide-and-conquer methodology. Given an array of items, a place is determined on the array on which to split the array and this is called the pivot point. All values greater than this point go to the right and all values less than this point go to the left. In this step, you have two arrays. The same process is applied to these arrays until there are no elements left to sort.

快速排序是一种使用分治法的排序方法。
给定一个项目数组，在数组上确定一个位置来分割数组，这称为枢轴点。
所有大于该点的值都将移至右侧，所有小于该点的值将移至左侧。
在此步骤中，您有两个数组。
对这些数组应用相同的过程，直到没有任何元素可供排序。

Quicksort has:

-   Worst case time complexity O(n^2)
最坏情况时间复杂度 O(n^2)

-   Average case time complexity O(n log n)
平均案例时间复杂度 O(n log n)
-   Best case time complexity O(n log n)
最好情况时间复杂度 O(n log n)
-   Space complexity O(n)
空间复杂度 O(n)

To perform quicksort, take the following steps:

-   Select a point on the list to pivot on.
-   Split the list into two lists, items to the left of the pivot and items to the right.
-   Set variables i to iterate from left to right on the left of the pivot. Set variable j to repeat from right to left on the left side of the pivot.
-   The variables i on the left look for a value greater than or equal to the pivot. Variables j on the right look for a value less than or equal to the pivot. 
-   When j < i, the values at these index locations are swapped, this is repeated until i and j meet at the pivot point.
-   Partition the list values into two lists, one to the left and one to the right of the pivot. Repeat the process on each of the resulting arrays.
-   Recursively apply the algorithm.

在列表中选择一个点作为旋转轴。
将列表拆分为两个列表，即枢轴左侧的项目和右侧的项目。
将变量 i 设置为在枢轴左侧从左到右迭代。将变量 j 设置为在枢轴左侧从右到左重复。
左侧的变量 i 寻找大于或等于主元的值。右侧的变量 j 查找小于或等于主元的值。
当 j < i 时，交换这些索引位置的值，重复此过程，直到 i 和 j 在枢轴点相遇。
将列表值分为两个列表，一个位于数据透视表的左侧，一个位于数据透视表的右侧。对每个结果数组重复该过程。

递归地应用该算法。


The pseudocode below for quicksort is done recursively.

```
// 快速排序
QuickSort(List, low, high)
  if(low<high) 
    pivot=partition(List, high, low)
  QuickSort(List, low, pivot-1)
  QuickSort(List, pivot+1, high) 

// 分区
Partition(List,high,low)
  pivot=arr[high]
  i=(low-1)
  for j = low; j <= high-1; j++) 
    if(List[j] < pivot)
      i++
      swap(List[i], List[j]) 
   swap(arr[i+1], List[j]) 
   return I + 1 
```

-   Starting at the leftmost element, each subsequent element is checked, and if it is found to be less, it is swapped.
-   从最左边的元素开始，检查每个后续元素，如果发现小于，则进行交换。
-   Line 3 calls the partition method, which begins on line 8.
-   第 3 行调用从第 8 行开始的分区方法。
-   Line 10 determines the more significant element to be placed on the right side of the list. Line 10 sets a variable i to be assigned to the index of the smaller element. The variable j is then used to check the elements to the right from which to make a comparison with the current smallest element.
-   Line 12 determines if there is to be a swap, a smaller element on the right will require moving to the current index position. Line 4 is for sorting the left array.
-   Line 5 is for sorting the right array. At each iteration, the size of the array to be sorted is halved. The arrays will continually break down until only one element is left in the subarrays. The result of calling partition will determine the location of the current element. This location is incremented and repeated until every element rests in its naturally ordered position.


Things to consider when evaluating this algorithm:

1.  Worst case scenario: this happens when the most significant element is consistently chosen as a pivot point. This will cause a loop to iterate over every element n from the left. The split will cause a search of every element on the right with none on the left, O(n^2).
2.  Average case scenario: an average pivot point is selected at every call. This will reduce the number of additional iterations required. So, there will be n iterations and an ever-decreasing logn iterative calls, O(n\*logn).
3.  Best case scenario: The middle value is always selected, and the iteration space is halved at every iteration, O(n\*logn).
4.  The iterative nature of the algorithm will impact the space complexity because the function call and variables are retained on the stack while the calculations are performed. However, the decision to use an in-place swap means no new array needs to be created, O(log n).

**Conclusion**

Two different sorting approaches have been broken down and analyzed through the lens of Big-O space and complexity. It has been shown that quicksort is more complex in implementation but returns overall quicker solutions. Selection sort is more simplistic and less code-heavy and requires less space, but will not generate results as effectively.

In this reading, you explored time and space complexity in both the selection sort and quicksort algorithms.

# Working with time complexity

## Introduction

In this reading, you will explore a worked example of a piece of code written in Python, along with how you would evaluate it using Big-O notation.

Evaluating an application's performance ensures that the code written is good and fit for purpose. The question is how do we evaluate efficiency? When we measure electricity, we use kilowatt-hours, which means how many kilowatts an appliance will use if it runs for an hour. The appliance will not always run for an hour, and it may have different requirements depending on the setting used, it is more of a general rule-of-thumb for evaluating cost.

评估应用程序的性能可确保编写的代码良好且适合用途。 问题是我们如何评价效率？ 当我们测量电量时，我们使用千瓦时，这意味着设备运行一小时将使用多少千瓦。 该设备不会总是运行一个小时，并且根据所使用的设置，它可能有不同的要求，这更多的是评估成本的一般经验法则。

When evaluating coding solutions, Big-O notation is used. So, Big-O notation is the kilowatt hour of code evaluation. It can be applied to measuring how much time a piece of code will take or how much space it will use in memory. Not all processors will run at the same speed, so instead of timing an application, you count the number of instructions an application initiates.

在评估编码解决方案时，使用 Big-O 表示法。 因此，Big-O 表示法是代码评估的千瓦时。 它可以应用于测量一段代码将花费多少时间或将在内存中使用多少空间。 并非所有处理器都以相同的速度运行，因此您无需对应用程序计时，而是计算应用程序启动的指令数。

## Which measurement reflects the quickest possible execution of some code?

哪个测量反映了某些代码的最快执行速度？

Let's explore which measurement reflects the quickest possible execution of some code.

让我们探讨哪种测量反映了某些代码的最快执行速度。

### O(1)

You use a constant time algorithm that takes O(1) (O-of-one) time to compute. This determines that it will only take one computation to complete a task. An example of this is to print an item from an array.
您使用恒定时间算法，计算时间为 O(1)（O-of-one）。 这决定了只需要一次计算即可完成一项任务。 一个例子是打印数组中的一个项目。

```py
# An array with 5 numbers 
array = [0,1,2,3,4]

# retrieve the number found at index location 3 
print(array[3]) 
```

In this instance, no matter how many values exist in the array, the approach has a Big-O of one. This means that running this code is considered O(1).

### O(n)

Next, let's explore an example of O(n). Taking the same array, an if statement is written that looks for the number 5. To establish that 5 is not there, it has to check every item in the array.

```py

# An array with 5 numbers 
array = [0,1,2,3,4] 

if 5 in array:
 print("five is alive")
```

In the above example, there is no 5, so there is no printout. To establish this, five checks were made on this array. As the input n = 5, this code is said to have a Big – O of O(n). To better understand this, let's extend the array to 10, leaving out the 5.

```py

# an array with 10 numbers 
array = [0,1,2,3,4,6,7,8,9,10]

if 5 in array:
 print("five is still alive")
```

By extending the array 10 integers, the number of computations has now become 10. This is still called O(n) because the input size is 10, which is how many checks must be made before the program ends.
通过将数组扩展为 10 个整数，计算次数现在变为 10。这仍然称为 O(n)，因为输入大小为 10，这是程序结束之前必须进行的检查次数。

### O(log n)

This search is less intensive than O(n) but more work than O(1). O(log n) is a logarithmic search and it will increase as new inputs are added but these inputs only offer marginal increases. An excellent example of this in action is a binary search. Binary search is covered in more detail later in the course.

Now, imagine playing a guessing game with the following prompts: too high, too low, or correct. You are given a range of 100 to 1. You may decide to approach the problem systematically. First, you guess 50 – too high. So, you guess 25 – which is too high. You may choose then to go 12 or 13. What is happening here is that you are halving the search space with each guess.

So, while the input to this function was 100 using a binary search approach, you should come upon the answer in under 5 or 6 guesses. This solution would have a time complexity of O(log n). Even if n (the range of numbers entered) is ten times bigger. It will not take ten times as many guesses.

Here is a breakdown of those steps on the array.

```py

array = \[0,1,2,3,4,6,7,8,9,10\]

print("##Step One")

print("Array")

print(array)

midpoint = int(len(array)/2)

print("the midpoint at step one is: " , array\[midpoint\])

print()

print("##Step Two")

array = array\[:midpoint\] # 6 is the midpoint of the array 

print("Array")

print(array)

# running this shows the numbers left to check 

# is 5 < 3 

# no 

# so discard the left hand side 

# so the array is halved again 

midpoint=int(len(array)/2)

print("the midpoint is: ",  array\[midpoint\])

print()

print("##Step Three") 

array = array\[midpoint:\] # so the array is halved at the midpoint

print(array)

# check for the midpoint 

midpoint=int(len(array)/2)

print("the midpoint is: " , array\[midpoint\])

# is 4 < 5 

# yes look to the right

print()

print("##Step Four") 

print(array\[midpoint:\]) 

# check for the midpoint 

array = array\[midpoint:\] # so the array is halved at the midpoint

midpoint=int(len(array)/2)
```

You will notice that to determine if 5 is present, it took 5 steps. That is a big-O score of O(5). You can see that this is bigger than O(1) but smaller than O(n). Now, what happens when the array is extended to 100? When looking for a number in an array of 10, it took 5 guesses. Looking at an array of 100 will not take 50 guesses; it will take no more than 10. Equally, if the list is extended to 1000, the guesses will only go up to 15-20.

From this, we can see that it is not O(1) because the answer is not immediate. It is not big-O(n) because the number of guesses does not go up with the size n of the array. So here, one says that the complexity is O(log(n)).

To gain greater insight into how the log values are only a gradual rise, look at a log table up to 100,000,000. This lens shows that O(log n) incurs only a minimal processing cost. Running a binary search on an array with any n values will, in a worst-case scenario, always make the number of computations found in the log values column.

![Table with log values](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/RNlpuXOAQeCug3r_qI066A_80356e91adc4416a85da712e9a54e8e1_Time-complexity-image-5.png?expiry=1701907200000&hmac=i3U0x-AcZzrtGHnliuoi1Y9oYgccTrdfjpAMcP9e5ps)

O(n^2) is heavy on computation. This is quadratic complexity, meaning that the work is doubled for every element in the array. An excellent way to visualize this is to consider that you have a variety of arrays. In keeping with the earlier example, let's explore the following code:

```py

new\_array=\[\] # an array to hold all of the results 

# array with five numbers 

array = \[0,1,2,3,4\]

for i in range(len(array)): # the array has five values, so this is n=5 

 for j in range(len(array)): # still the same array so n = 5 

 new\_array.append(i\*j) # every computation made is stored here 

print(len(new\_array)) #how big is this new array ? 
```

The first loop will equal the number of elements input, n. The second loop will also look at the number of input elements, n. So, the overall complexity of running this approach can be said to be n\*n which is n^2 (n-squared). To find out how many computations were made, you have to print out the number of times n was used in the loop as below.

```py
n = 5 #size of array 

print(n\*n) # how big is this new array ? 
```

If you know that the array has 25 elements, then you understand the principles of calculating Big-O notation. To further test your knowledge, how many computations would be required if n = 6? Meaning the array had 6 values? The answer is 6 x 6 so 36.

## Visual representation of the problem

Below is a graphical representation of how n relates to the number of computations taken.

![Graphical representation of how n relates to the number of computations.](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/IGySTDFdRFCkwd9ZdoQTnw_382da9f238024333aca779375c0e5ce1_Picture-1-1-.png?expiry=1701907200000&hmac=RQV5q2wZFo-ho465WmtbhvHNQQuSFiEtEw64ijeatuQ)

As you can see, the best time to aim for is O(1); O(log n) is still excellent. O(n) is ok and O(n^2) is not great.

## Worst case, best case and average case

最坏情况、最好情况和平均情况

Of course, it is not always possible to tell how long an approach will take. When looking at the initial loop example, there was a search performed for an element that was absent. You can say that to search a loop takes O(n) times but this might not always be the case.

Consider that the item being searched for is the first in the array. Then the return will be pretty good in O(1) time! In the example provided every item must be searched before determining that it was absent: O(n) time. The middle case would be that it is found around the middle of the loop O(n/2). When evaluating an approach, three definitions are used: best case, worst case and average case.

当然，并不总是能够知道接近需要多长时间。 在查看初始循环示例时，对不存在的元素执行了搜索。 您可以说搜索循环需要 O(n) 次，但情况可能并不总是如此。

考虑正在搜索的项目是数组中的第一项。 那么在 O(1) 时间内的回报将会相当不错！ 在提供的示例中，必须先搜索每个项目，然后才能确定它不存在：O(n) 时间。 中间的情况是它是在循环 O(n/2) 的中间找到的。 在评估一种方法时，使用三种定义：最佳情况、最坏情况和平均情况。

## Conclusion

This reading introduced the notion of time in relation to complexity and you explored a worked example of a piece of code written in Python. You also investigated how you would evaluate it using Big-O notation.

A good question to ask yourself before you start is, "how many computations does my solution employ and is there a better way?" Now that you know how to use a metric to evaluate the solution to a given problem, you can start thinking of its efficacy concerning time complexity.
本阅读介绍了与复杂性相关的时间概念，并且您探索了用 Python 编写的一段代码的有效示例。 您还研究了如何使用 Big-O 表示法对其进行评估。

在开始之前问自己一个好问题是：“我的解决方案使用了多少计算量，是否有更好的方法？” 现在您知道如何使用度量来评估给定问题的解决方案，您可以开始考虑其在时间复杂性方面的功效。